{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX8gZlVyCCbz"
      },
      "source": [
        "# Modelos del lenguaje con RNNs\n",
        "\n",
        "En esta parte, vamos a entrenar un modelo del lenguaje basado en caracteres con Recurrent Neural Networks. Asimismo, utilizará el modelo para generar texto. En particular,su modelo tiene obras de la literatura clásica en castellano para obtener una red neuronal que sea capaz de \"escribir\" fragmentos literarios.\n",
        "\n",
        "Los entrenamientos para obtener un modelo de calidad podrían tomar cierto tiempo (5-10 minutos por epoch), tener presente que GPU no funciona tan bien con LSTM, por tanto el modelo se debe generar con tiempo. \n",
        "\n",
        "El dataset a utilizar contiene un archivo de texto con el contenido del castellano antiguo de **El Ingenioso Hidalgo Don Quijote de la Mancha**, disponible de manera libre en la página de [Project Gutenberg](https://www.gutenberg.org). Asimismo, usted podrá utilizar otras clases de texto\n",
        "\n",
        "[El ingenioso hidalgo Don Quijote de la Mancha (Miguel de Cervantes)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io)\n",
        "\n",
        "[Compilación de obras teatrales (Calderón de la Barca)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219433&authkey=AKvGD6DC3IRBqmc)\n",
        "\n",
        "[Trafalgar (Benito Pérez Galdós)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219434&authkey=AErPCAtMKOI5tYQ)\n",
        "\n",
        "verifique los datos antes de comenzar "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI274F8LQC59"
      },
      "source": [
        "## 1. Carga y procesado del texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZNnzvXuqVVm"
      },
      "source": [
        "Primero, descargue el libro e inspeccionar los datos. El fichero a descargar es una versión en .txt del libro de Don Quijote, a la cual se le han borrado introducciones, licencias y otras secciones para dejarlo con el contenido real de la novela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7tKOZ9BFfki"
      },
      "source": [
        "import numpy as np \n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "import sys\n",
        "import random\n",
        "import io\n",
        "\n",
        "path = keras.utils.get_file(\n",
        "    fname=\"don_quijote.txt\", \n",
        "    origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYGLvjLXrUUd"
      },
      "source": [
        "Cundo lea el documento trate de colocar en minuscula el texto para que sea más facil de elaborar.\n",
        "\n",
        "**1.1.** Leer todo el contenido del texto en una única variable ***text*** y convertir el string a minúsculas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WB6FejrrTu9"
      },
      "source": [
        "with open(path, encoding=\"utf8\") as f:\n",
        "  text = f.read().lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knyzgX0XnGfm"
      },
      "source": [
        "#len(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkgGl8GWtUk8"
      },
      "source": [
        "Puede comprobar que se ha realizado la variación y que el texto se encuentra en minuscula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMFhe3COFwSD"
      },
      "source": [
        "print(\"Longitud del texto: {}\".format(len(#Escriba su codigo aqui)))\n",
        "print(text[0:500])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ7TUXWiyvOj"
      },
      "source": [
        "## 2. Procesado de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x66_Vi_Gyxns"
      },
      "source": [
        "Una de las grandes ventajas de trabajar con modelos que utilizan caracteres en vez de palabras es que no necesita tokenizar el texto (partirlo palabra a palabra). Su modelo funcionará directamente con los caracteres en el texto, incluyendo espacios, saltos de línea, etc.\n",
        "\n",
        "Antes de hacer el ejercicio, debe procesar el texto en entradas y salidas compatibles el modelo. Como sabe, un modelo del lenguaje con RNNs acepta una serie de caracteres y predice el siguiente carácter en la secuencia.\n",
        "\n",
        "* \"*El ingenioso don Qui*\" -> predicción: **j**\n",
        "* \"*El ingenioso don Quij*\" -> predicción: **o**\n",
        "\n",
        "De modo que la entrada y la salida de su modelo necesita ser algo parecido a este esquema. En este punto, podría usar dos formas de preparar los datos para este modelo.\n",
        "\n",
        "1. **Secuencia a secuencia**. La entrada del modelo sería una secuencia y la salida sería esa secuencia trasladada un caracter a la derecha, de modo que en cada instante de tiempo la RNN tiene que predecir el carácter siguiente. Por ejemplo:\n",
        "\n",
        ">* *Input*:   El ingenioso don Quijot \n",
        ">* *Output*: l ingenioso don Quijote\n",
        "\n",
        "2. **Secuencia a carácter**. En este variante, pasa una secuencia de caracteres por la RNN y, al llegar al final de la secuencia, se predice el siguiente carácter.\n",
        "\n",
        ">* *Input*:   El ingenioso don Quijot \n",
        ">* *Output*: e\n",
        "\n",
        "En este trabajo, por simplicidad, se utilizará la segunda variante.\n",
        "Utilice secuencias de tamaño *SEQ_LENGTH* caracteres (y elija el hiperparámetro ).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkfJUIxW5m5C"
      },
      "source": [
        "#### 2.1. Obtención de los caracteres y mapas de caracteres\n",
        "\n",
        "Antes que nada, necesita saber qué caracteres aparecen en el texto, ya que tiene que diferenciarlos mediante un índice de 0 a *num_chars* - 1 en el modelo. Obtener:\n",
        " \n",
        "\n",
        "1.   Número de caracteres únicos que aparecen en el texto.\n",
        "2.   Diccionario que asocia char a índice único entre 0 y *num_chars* - 1. Por ejemplo, {'a': 0, 'b': 1, ...}\n",
        "3.   Diccionario reverso de índices a caracteres: {0: 'a', 1: 'b', ...}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bJ0NsbCbupF"
      },
      "source": [
        "chars=sorted(list(set(\"escriba su texto aqui\")))\n",
        "char_indices = dict((c,i) for i, c in enumerate(\"escriba su codigo aqui\"))\n",
        "indice_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTMi-94I7HKi"
      },
      "source": [
        "#indice_char\n",
        "char_indices\n",
        "#len(chars) # se obtienen 61 caracteres"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_B4AWo0ElwA"
      },
      "source": [
        "#### 2.2. Obtención de secuencias de entrada y carácter a predecir\n",
        "\n",
        "Ahora, obtenga la secuencias de entrada en formato texto y los correspondientes caracteres a predecir. Para ello, recorra el texto completo leído anteriormente, obteniendo una secuencia de SEQ_LENGTH caracteres y el siguiente caracter a predecir. Una vez hecho, mueva un carácter a la izquierda y hacer lo mismo para obtener una nueva secuencia y predicción. Guarde las secuencias en una variable ***sequences*** y los caracteres a predecir en una variable ***next_chars***.\n",
        "\n",
        "Por ejemplo, si el texto fuera \"Don Quijote\" y SEQ_LENGTH fuese 5, tendríamos\n",
        "\n",
        "* *sequences* = [\"Don Q\", \"on Qu\", \"n Qui\", \" Quij\", \"Quijo\", \"uijot\"]\n",
        "* *next_chars* = ['u', 'i', 'j', 'o', 't', 'e']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NslxhnnDK6uA"
      },
      "source": [
        "# Definia el tamaño de las secuencias. Puede dejar este valor por defecto.\n",
        "SEQ_LENGTH = 35\n",
        "step=3\n",
        "rawX = []\n",
        "rawy = []\n",
        "\n",
        "for i in range(0, len(#escriba su codigo aqui) - SEQ_LENGTH, step):\n",
        "    rawX.append(text[i: i+SEQ_LENGTH])\n",
        "    rawy.append(text[i+SEQ_LENGTH])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y3AmjYtHdLJ"
      },
      "source": [
        "Indicar el tamaño del training set que acabamos de generar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVWqKxFcbwTu"
      },
      "source": [
        "## SU CÓDIGO AQUÍ\n",
        "#n_sentences=len(rawX)\n",
        "#n_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goGQkKcwpLRJ"
      },
      "source": [
        "Como el Quijote es muy largo y tiene muchas secuencias, puede encontrar problemas de memoria. Por ello, elegija un número máximo de ellas. Si estás corriendo esto localmente y tienes problemas de memoria, puedes reducir el tamaño aún más, pero tenga cuidado porque, a menos datos, peor calidad del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97SXdkJX7HKw"
      },
      "source": [
        "MAX_SEQUENCES = 500000\n",
        "\n",
        "perm = np.random.permutation(len(rawX)) #Permutar aleatoriamente una secuencia, o devolver un rango permutado.\n",
        "rawX, rawy = np.array(rawX), np.array(rawy) \n",
        "rawX, rawy = rawX[perm], rawy[perm]\n",
        "rawX, rawy = list(rawX[:MAX_SEQUENCES]), list(rawy[:MAX_SEQUENCES])\n",
        "\n",
        "print(len(rawX))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FzgtAbPIs6f"
      },
      "source": [
        "#### 2.3. Obtención de input X y output y para el modelo\n",
        "\n",
        "Finalmente, a partir de los datos de entrenamiento que hemos generado vamos a cree los arrays de datos X e y que pasará a su modelo.\n",
        "\n",
        "Para ello, utilice *one-hot encoding* para el caracteres. Por ejemplo, si sólo tiene 4 caracteres (a, b, c, d), las representaciones serían: (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) y (0, 0, 0, 1).\n",
        "\n",
        "De este modo, **X** tendrá shape *(num_sequences, seq_length, num_chars)* e **y** tendrá shape *(num_sequences, num_chars)*. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBwJi3_Dsb2x"
      },
      "source": [
        "X = np.zeros((len(rawX), SEQ_LENGTH , len(chars)))\n",
        "y = np.zeros((len(rawX), len(chars)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F7lUsqLs5T9"
      },
      "source": [
        "for i, sentence in enumerate(rawX):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[rawy[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxeUxz3HPm3l"
      },
      "source": [
        "## 3. Definición del modelo y entrenamiento\n",
        "\n",
        "Una vez tiene todo,  defina el modelo. Defina un modelo que utilice una **LSTM** con **128 unidades internas**. Si bien el modelo puede definirse de una manera más compleja, para empezar debería bastar con una LSTM más una capa Dense con el *softmax* que predice el siguiente caracter a producir. Adam puede ser una buena elección de optimizador.\n",
        "\n",
        "Una vez el modelo esté definido, entrénelo un poco para asegurarse de que la loss es decreciente. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSw2j0btYWZs"
      },
      "source": [
        "model= Sequential()\n",
        "model.add(LSTM(\"escriba su codigo aqui\", input_shape=(SEQ_LENGTH, len(chars))))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(chars), activation= \"ESCRIBA SU CODIGO AQUI\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYrEhi3mxQoY"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B9RW3-Qxcf9"
      },
      "source": [
        "#model.fit(X, y, batch_size=128, epochs=20, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yUFHS4kHkyY"
      },
      "source": [
        "Para ver cómo evoluciona SU modelo del lenguaje,  genere texto según va entrenando. Para ello, programe una función que, utilizando el modelo en su estado actual, genere texto, con la idea de ver cómo se va generando texto al entrenar cada epoch.\n",
        "\n",
        "En el código de abajo puede ver una función auxiliar para obtener valores de una distribución multinomial. Esta función se usará para muestrear el siguiente carácter a utilizar según las probabilidades de la salida de softmax (en vez de tomar directamente el valor con la máxima probabilidad, obtiene un valor aleatorio según la distribución de probabilidad dada por softmax, de modo que los resultados serán más diversos, pero seguirán teniendo \"sentido\" ya que el modelo tenderá a seleccionar valores con más probabilidad).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoGYpWOHd7Lr"
      },
      "source": [
        "def sample(probs, temperature=1.0):\n",
        "    \"\"\"Nos da el índice del elemento a elegir según la distribución\n",
        "    de probabilidad dada por probs.\n",
        "    \n",
        "    Args:\n",
        "      probs es la salida dada por una capa softmax:\n",
        "        probs = model.predict(x_to_predict)[0]\n",
        "      \n",
        "      temperature es un parámetro que nos permite obtener mayor\n",
        "        \"diversidad\" a la hora de obtener resultados. \n",
        "        \n",
        "        temperature = 1 nos da la distribución normal de softmax\n",
        "        0 < temperature < 1 hace que el sampling sea más conservador,\n",
        "          de modo que sampleamos cosas de las que estamos más seguros\n",
        "        temperature > 1 hace que los samplings sean más atrevidos,\n",
        "          eligiendo en más ocasiones clases con baja probabilidad.\n",
        "          Con esto, tenemos mayor diversidad pero se cometen más\n",
        "          errores.\n",
        "    \"\"\"\n",
        "    # Cast a float64 por motivos numéricos\n",
        "    probs = np.asarray(probs).astype('float64')\n",
        "    \n",
        "    # logaritmo de probabilidades y aplicamos reducción\n",
        "    # por temperatura.\n",
        "    probs = np.log(probs) / temperature\n",
        "    \n",
        "    # Volvemos a aplicar exponencial y normalizamos de nuevo\n",
        "    exp_probs = np.exp(probs)\n",
        "    probs = exp_probs / np.sum(exp_probs)\n",
        "    \n",
        "    # Hacemos el sampling dadas las nuevas probabilidades\n",
        "    # de salida (ver doc. de np.random.multinomial)\n",
        "    samples = np.random.multinomial(1, probs, 1)\n",
        "    return np.argmax(samples)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fejfZldd4ou"
      },
      "source": [
        "Utilizando la función anterior y el modelo entrenado, añadir un callback a al modelo para que, según vaya entrenando, se vean los valores que resultan de generar textos con distintas temperaturas al acabar cada epoch.\n",
        "\n",
        "Para ello, abajo tienedisponible el callback *on_epoch_end*. Esta función elige una secuencia de texto al azar en el texto disponible en la variable\n",
        "text y genera textos de longitud *GENERATED_TEXT_LENGTH* según las temperaturas en *TEMPERATURES_TO_TRY*, utilizando para ello la función *generate_text*.\n",
        "\n",
        "Complete la función *generate_text* de modo que utilice el modelo y la función sample para generar texto.\n",
        "\n",
        "NOTA: Cuando haga model.predict, es aconsejable usar verbose=0 como argumento para evitar que la función imprima valores de salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOEZvnBXkODd"
      },
      "source": [
        "TEMPERATURES_TO_TRY = [0.2] #, 0.5, 1.0, 1.2]\n",
        "GENERATED_TEXT_LENGTH = 300\n",
        "\n",
        "def generate_text(seed_text, model, length=300, temperature=1, max_length=30):\n",
        "    \"\"\"Genera una secuencia de texto a partir de seed_text utilizando model.\n",
        "    \n",
        "    La secuencia tiene longitud length y el sampling se hace con la temperature\n",
        "    definida.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Aquí guardaremos nuestro texto generado, que incluirá el\n",
        "    # texto origen\n",
        "    generated = seed_text\n",
        "    \n",
        "    # Utilizar el modelo en un bucle de manera que generemos\n",
        "    # carácter a carácter. Habrá que construir los valores de\n",
        "    # X_pred de manera similar a como hemos hecho arriba, salvo que\n",
        "    # aquí sólo se necesita una oración\n",
        "    # Nótese que el x que utilicemos tiene que irse actualizando con\n",
        "    # los caracteres que se van generando. La secuencia de entrada al\n",
        "    # modelo tiene que ser una secuencia de tamaño SEQ_LENGTH que\n",
        "    # incluya el último caracter predicho.\n",
        " \n",
        "    ### TU CÓDIGO AQUÍ\n",
        "    prediction = []    \n",
        "    \n",
        "    for i in range(length):\n",
        "        # Make numpy array to hold seed\n",
        "        X = np.zeros((1, len(generated), len(chars) ))\n",
        "        \n",
        "        # Set one-hot vectors for seed sequence\n",
        "        for t, char in enumerate(seed_text):\n",
        "            X[0, t, char_indices[char]] = 1\n",
        "        \n",
        "        # Generate prediction for next character\n",
        "        preds = model.predict(X, verbose=0)[0]\n",
        "        # Choose a character from the prediction probabilities\n",
        "        next_index = sample(preds,0.2)\n",
        "        next_char = indice_char[next_index]\n",
        "        \n",
        "        prediction.append(next_char)\n",
        "        # Add the predicted character to the seed sequence so the next prediction\n",
        "        # includes this character in it's seed.\n",
        "        #generated += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "\n",
        "        print(next_char, end= \" \");\n",
        "        # Flush so we can see the prediction as it's generated\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    prediction = ''.join(prediction)\n",
        "    sys.stdout.flush()\n",
        "    \n",
        "    ### FIN DE TU CÓDIGO\n",
        "    return generated\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "  print(\"\\n\\n\\n\")\n",
        "  \n",
        "  # Primero, seleccionamos una secuencia al azar para empezar a predecir\n",
        "  # a partir de ella\n",
        "  start_pos = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "  seed_text = text[start_pos:start_pos + SEQ_LENGTH]\n",
        "  for temperature in TEMPERATURES_TO_TRY:\n",
        "    print(\"------> Epoch: {} - Generando texto con temperature {}\".format(\n",
        "        epoch + 1, temperature))\n",
        "    \n",
        "    generated_text = generate_text(seed_text, model, \n",
        "                                   GENERATED_TEXT_LENGTH, temperature)\n",
        "    print(\"Seed: {}\".format(seed_text))\n",
        "    print(\"Texto generado: {}\".format(generated_text))\n",
        "\n",
        "\n",
        "generation_callback = LambdaCallback(on_epoch_end=on_epoch_end)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSMYZ2JdrSJg"
      },
      "source": [
        "Entrene ahora su modelo. No se olvides de añadir *generation_callback* a la lista de callbacks utilizados en fit(). Ya que las métricas de clasificación no son tan críticas aquí (no nos importa tanto acertar el carácter exacto, sino obtener una distribución de probabilidad adecuada), no es necesario monitorizar la accuracy ni usar validation data, si bien puedes añadirlos para asegurarte de que todo está en orden.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oT7pNvjrP2e"
      },
      "source": [
        "## TU CÓDIGO AQUÍ\n",
        "\n",
        "model.fit(X, y, \"su codigo\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBbmz9DMhVhc"
      },
      "source": [
        "## Entregable\n",
        "\n",
        "Complete los apartados anteriores para entrenar modelos del lenguaje que sean capaces de generar texto con cierto sentido. Comentar los resultados obtenidos y cómo el modelo va mejorando época a época. Comentar las diferencias apreciadas al utilizar diferentes valores de temperatura. Entregar al menos la salida de un entrenamiento completo con los textos generados época a época.\n",
        "\n",
        "El objetivo no es conseguir generar pasajes literarios con coherencia, sino obtener lenguaje que se asemeje en cierta manera a lo visto en el texto original y donde las palabras sean reconocibles como construcciones en castellano. Como ejemplo de lo que se puede conseguir, este es el resultado de generar texto después de 10 epochs y con temperature 0.2:\n",
        "\n",
        "\n",
        "```\n",
        "-----> Epoch: 10 - Generando texto con temperature 0.2\n",
        "Seed: o le cautivaron y rindieron el\n",
        "Texto generado: o le cautivaron y rindieron el caballero de la caballería de la mano de la caballería del cual se le dijo:\n",
        "\n",
        "-¿quién es el verdad de la caballería de la caballería de la caballería de la caballería de la caballería, y me ha de habían de la mano que el caballero de la mano de la caballería. y que no se le habían de la mano de la c\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJp9Ds55s2O-"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GneURbWZxN8d"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}